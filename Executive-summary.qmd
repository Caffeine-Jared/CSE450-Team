---
title: "Banco Federal de Finan√ßas Report"
subtitle: "Target Marketing Campaign"
author: "Team 4"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
    
---

```{python}
#| label: libraries
#| include: false
import numpy as np 
import pandas as pd
import altair as alt
url_bank = 'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bank.csv'

bank = pd.read_csv(url_bank)
```


## Background

_A major telemarketing campaign and the results were inadequete to come to a conclusion. We were assigned to impelment a Machine Learning Algorithim to help find the following:_

_1. Find interesting customer segments based on their previous marketing campaign._
_2. Find a way to identify the types of customers most likely to respond favorably to future marketing campaigns._
_3.Proving to a skeptical Senhor Ferreira that a targeted campaign based on data science will significantly outperform a campaign made up of randomly selected customers._

_Since we're operating in the European Union, we're subject to GDPR compliance requirements. The GDPR doesn't apply in this situation, since we're just building a model, not selling data. In order to use this data under GDPR, we'll need to get consent from the customers in the dataset. We are also using only historic data that has been put into an anonymous format so we will be compliant in that department as well._

## Recommendation
_._


## Methodology


_We decided that using a supervised approach would be ideal for this job because we are trying to classify our clientele would have interest in subscribing to a term deposit. Supervised approaches are better for getting a finite answer. When we took our data we decided that use eighty percent of the data for training and the remaining data for testing and validation. We chose this distribution due to this being a relatively small dataset and is the standard distribution for supervised learning models._

_Before we even started applying the data to our learning model. We needed to adjust some of our data to make it more usable. We changed how recently people had been contacted to move the people who had not been contacted into separate groups.  We also made it a point to put our numeric data in groups not using them as individuals._


## Results, Actions, and Limitations

_._


## Tree
_For our model, we decided to use the RandomForestClassifier which constructs multiple decision trees during the training phase and then combines their predictions to produce more accurate and stable results. We augmented the RandomForestClassifier using hyperparameters which controlled certain aspects of the final decision tree, including the number of trees in the forest, the max depth of each tree, and the number of samples required to split an internal node. The hyperparameters are determined by using GridSearchCV, which will search over a specified parameter grid, and determine the best parameters by which we should control the decision tree._

## Metrics

We decided the most important metric is recall. We wanted to make sure we get as many yes's with the least amount of calls. Then precesion is the next important. The data we validated our model with included 3,707 pepole. Of those people we predicted that 3,456 would say no and 251 would say yes. We had a 28.7% recall and a 52.2% precision. This means that our model only got around 30% of the people that said yes. But over half of the people the model said was a yes, would actually agree to the campaign. This means that every other person you call will agree to the campaign. So we weren't able to get all the people that would say yes, but we cut out over 3,100 calls out. So you would be able to save a lot of time and money cutting out all the other calls you would have been making.

```{python}
#| label: Matrix
#| include: false
from sklearn.utils import resample
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import RandomOverSampler
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
from sklearn.metrics import ConfusionMatrixDisplay


clean = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bank.csv')

# Create some new features
def create_new_features(data):
    data['last_contact'] = data['pdays'].apply(lambda x: 1 if x == 999 else 0)
    data['recent_contact'] = data['pdays'].apply(lambda x: 1 if x < 30 else 0)
    data['previous_contact'] = data['previous'].apply(lambda x: 1 if x > 0 else 0)

create_new_features(clean)

# Encode our features and target as needed
features = ['nr.employed', 'age', 'euribor3m', "campaign", 'cons.conf.idx', 'poutcome', 'last_contact', 'recent_contact', 'previous_contact']
X = pd.get_dummies(clean[features], drop_first=True)
y = clean['y']
# Split our data into training and test data
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)

# Use RandomOverSampler for oversampling
ros = RandomOverSampler(random_state=42)
X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)

# Define the parameter grid to search over
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Create a random forest classifier
clf = RandomForestClassifier(random_state=25, n_jobs=-1)

clf = RandomForestClassifier(n_estimators=50,
                              max_depth=30,
                              min_samples_split=2,
                              min_samples_leaf=1,
                              random_state=25, n_jobs=-1)

# Train the random forest classifier
clf.fit(X_train, y_train)

# Test the random forest classifier
y_pred = clf.predict(X_test)



```

```{python}
disp = ConfusionMatrixDisplay.from_estimator(
  clf,
  X_test,
  y_test,
  cmap=plt.cm.Blues,)
plt.show()
```

## Questions
__Types of customers respond better on certain days than others?__
```{python}
#| include: false
#| label: Chart functions

#======================Chart 1
filtered_bank2 = bank.loc[(bank['contact'] == 'cellular') | (bank['contact'] == 'telephone')]

# Compute the success rate of calling customers by contact type and job
success_rate = filtered_bank2.groupby(['contact', 'job'])['y'].value_counts(normalize=True).reset_index(name='success_rate')
success_rate = success_rate.loc[success_rate['y'] == 'yes']

# Create an Altair chart with the success rate
chart1 = alt.Chart(success_rate).mark_bar().encode(
    x=alt.X('job:N', axis=alt.Axis(title='Job Type')),
    y=alt.Y('success_rate:Q', axis=alt.Axis(format='.0%')),
    color=alt.Color('contact:N', legend=None),
    column=alt.Column('contact:N', header=alt.Header(title='Contact Type')),
    tooltip=[alt.Tooltip('success_rate:Q', format='.2%')],
).properties(
    width=200,
    title="Success Rate of Calling Customers by Contact Type and Job"
)
#=======================Chart 2
filtered_bank = bank.loc[(bank['contact'] == 'cellular') & (bank['marital'] != 'unknown') & (bank['job'] == 'student')]

# Compute value counts on the filtered DataFrame
counts = filtered_bank[['day_of_week', 'marital', 'y']].value_counts().reset_index()
counts.columns = ['day_of_week', 'marital', 'y', 'count']

# Define the desired order of the categories
day_order = ['mon', 'tue', 'wed', 'thu', 'fri']

# Apply the order to the day_of_week column of the counts DataFrame
counts = counts.sort_values(by=['day_of_week'], key=lambda x: pd.Categorical(x, categories=day_order))

# Create an Altair chart with the sorted x-axis
chart2 = alt.Chart(counts).mark_bar().encode(
    x=alt.X('day_of_week:N', sort=day_order),
    y='count:Q',
    color='y:N',
    column='marital:N'
).properties(
    width=100,
    title={
    "text": ["Data Distribution by Day of Week, Marital Status, and Y (Cellular Contacts Only)"],
    "subtitle" : ["Student Job Type"]}
)
#=======================Chart 3
filtered_bank3 = bank.loc[(bank['contact'] == 'cellular') & (bank['marital'] != 'unknown') & (bank['job'] == 'retired')]

# Compute value counts on the filtered DataFrame
counts2 = filtered_bank3[['day_of_week', 'marital', 'y']].value_counts().reset_index()
counts2.columns = ['day_of_week', 'marital', 'y', 'count']

# Define the desired order of the categories
day_order = ['mon', 'tue', 'wed', 'thu', 'fri']

# Apply the order to the day_of_week column of the counts DataFrame
counts2 = counts2.sort_values(by=['day_of_week'], key=lambda x: pd.Categorical(x, categories=day_order))

# Create an Altair chart with the sorted x-axis
chart1 = alt.Chart(counts2).mark_bar().encode(
    x=alt.X('day_of_week:N', sort=day_order),
    y='count:Q',
    color='y:N',
    column='marital:N'
).properties(
    width=100,
    title={
        "text":["Data Distribution by Day of Week, Marital Status, and Y (Cellular Contacts Only)"],
        "subtitle":["Retired Job Type"]}
)
```

```{python}
#chart3
```
_We wanted to see which of the two methods of contact would have the highest success rate from the marketing campaign. As you can see, Contacting people using a Cellular device would be more benificial than call those with a telephone. We also can see that Retired and Student have a 31.59% and 36.33% chance of a success rate._

```{python}
#chart2
```
_Looking more into the Student side in which day would be best and to know if they were Divorced,Married, or Single had help drill in our target audience. Based on Single section, we can see that during the middle of the week has a higher chance of gaining a successful call. We also see that we gain nothing by calling Divorced Students._
```{python}
#chart1
```
_Looking more into the Retired side, we also wanted to know which marital status would be best to call. The pattern for Retired and Students seems to be the same where they would be more successfull by calling in the middle of the week (Tueday through Thrursday) than any other week._

## Python Notebooks
